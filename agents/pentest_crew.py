from crewai import Agent, Task, Crew, Process
from crewai.tools import BaseTool
# from crewai.tools import SerperDevTool, WebsiteSearchTool  # These might not be available in current version
from models.ollama_manager import OllamaManager
from tools import ToolManager
import asyncio
from typing import Dict, Any, Optional, List
import logging
from pydantic import Field
from mongodb_integration import CrewAIMongoDB
import json
import uuid
from datetime import datetime

logger = logging.getLogger(__name__)

class LoggingAgent:
    """Wrapper for CrewAI Agent that logs all actions to MongoDB"""
    
    def __init__(self, agent: Agent, mongodb: CrewAIMongoDB, session_id: str):
        self.agent = agent
        self.mongodb = mongodb
        self.session_id = session_id
        self.role = agent.role
        
    def log_action(self, action_type: str, data: Dict[str, Any]):
        """Log agent action to MongoDB"""
        if self.mongodb.is_connected():
            self.mongodb.store_agent_action(
                agent_role=self.role,
                action_type=action_type,
                action_data=data,
                pentest_session_id=self.session_id
            )
    
    def execute_task(self, task: Task) -> str:
        """Execute task with logging"""
        self.log_action("task_start", {
            "task_description": task.description,
            "expected_output": task.expected_output,
            "started_at": datetime.utcnow().isoformat()
        })
        
        try:
            # Execute the actual task
            result = self.agent.execute_task(task)
            
            self.log_action("task_complete", {
                "task_description": task.description,
                "result": str(result),
                "success": True,
                "completed_at": datetime.utcnow().isoformat()
            })
            
            return result
            
        except Exception as e:
            self.log_action("task_error", {
                "task_description": task.description,
                "error": str(e),
                "success": False,
                "completed_at": datetime.utcnow().isoformat()
            })
            raise

class PentestTool(BaseTool):
    """Custom tool wrapper for penetration testing tools with MongoDB logging"""
    tool_name: str = Field(description="Name of the underlying tool")
    tool_description: str = Field(description="Description of what the tool does")
    tool_manager: ToolManager = Field(description="Tool manager instance")
    mongodb: CrewAIMongoDB = Field(description="MongoDB instance for logging")
    session_id: str = Field(description="Session ID for grouping logs")
    
    @property 
    def name(self) -> str:
        return f"{self.tool_name}_scanner"
    
    @property
    def description(self) -> str:
        return self.tool_description
    
    def _run(self, target: str, **kwargs) -> str:
        """Execute the tool and return results with comprehensive logging"""
        # Log tool execution start
        self.mongodb.store_command_execution(
            command=f"{self.tool_name} scan on {target}",
            output="Tool execution started",
            success=True,
            context={
                "tool_name": self.tool_name,
                "target": target,
                "kwargs": kwargs,
                "session_id": self.session_id,
                "stage": "start"
            }
        )
        
        try:
            tool = self.tool_manager.get_tool(self.tool_name)
            result = tool.scan(target, **kwargs)
            
            # Log successful tool execution
            self.mongodb.store_command_execution(
                command=f"{self.tool_name} scan on {target}",
                output=result.output,
                success=result.success,
                context={
                    "tool_name": self.tool_name,
                    "target": target,
                    "kwargs": kwargs,
                    "session_id": self.session_id,
                    "stage": "complete",
                    "metadata": result.metadata
                }
            )
            
            # Store detailed tool results
            self.mongodb.store_tool_result(self.tool_name, target, {
                "success": result.success,
                "output": result.output,
                "metadata": result.metadata,
                "kwargs": kwargs,
                "session_id": self.session_id
            })
            
            return f"Tool: {self.tool_name}\nTarget: {target}\nResult: {result.output}\nSuccess: {result.success}\nMetadata: {result.metadata}"
            
        except Exception as e:
            # Log tool execution error
            self.mongodb.store_command_execution(
                command=f"{self.tool_name} scan on {target}",
                output=f"Error: {str(e)}",
                success=False,
                context={
                    "tool_name": self.tool_name,
                    "target": target,
                    "kwargs": kwargs,
                    "session_id": self.session_id,
                    "stage": "error",
                    "error": str(e)
                }
            )
            
            return f"Tool: {self.tool_name} failed with error: {str(e)}"

class TaskPlanner:
    """AI-powered task planning system that guides agents based on model decisions"""
    
    def __init__(self, ollama_manager: OllamaManager, mongodb: CrewAIMongoDB, session_id: str):
        self.ollama_manager = ollama_manager
        self.mongodb = mongodb
        self.session_id = session_id
        self.task_history = []
        
    def analyze_current_state(self, target: str) -> Dict[str, Any]:
        """Analyze current penetration testing state and results"""
        current_state = {
            "target": target,
            "completed_tools": [],
            "findings": [],
            "vulnerabilities": [],
            "next_recommendations": []
        }
        
        # Get recent tool results for this session
        tool_results = self.mongodb.get_tool_results(target=target, limit=20)
        
        for result in tool_results:
            if result.get("session_id") == self.session_id:
                tool_name = result.get("tool_name", "unknown")
                current_state["completed_tools"].append(tool_name)
                
                # Extract findings and vulnerabilities from tool output
                output = result.get("result", {}).get("output", "")
                if "vulnerability" in output.lower() or "exploit" in output.lower():
                    current_state["vulnerabilities"].append({
                        "tool": tool_name,
                        "finding": output[:200] + "..." if len(output) > 200 else output
                    })
                
                if output and len(output) > 10:  # Has meaningful output
                    current_state["findings"].append({
                        "tool": tool_name,
                        "summary": output[:150] + "..." if len(output) > 150 else output
                    })
        
        return current_state
    
    def decide_next_task(self, target: str, agent_role: str) -> Dict[str, Any]:
        """Use AI model to decide the next best task for an agent"""
        current_state = self.analyze_current_state(target)
        
        # Prepare prompt for the AI model
        prompt = f"""
        You are an expert penetration testing coordinator. Based on the current state of the penetration test, decide the next best action for the {agent_role}.

        Target: {target}
        Completed Tools: {current_state['completed_tools']}
        Current Findings: {len(current_state['findings'])} findings discovered
        Vulnerabilities Found: {len(current_state['vulnerabilities'])} potential vulnerabilities

        Available Tools: nmap, nikto, sqlmap, burp, zap, hydra, enum4linux, john, wireshark, metasploit

        Recent Findings Summary:
        {json.dumps(current_state['findings'][-3:], indent=2) if current_state['findings'] else "No findings yet"}

        Based on this information, decide:
        1. What should be the next tool to run?
        2. What specific parameters or focus areas should be used?
        3. What is the reasoning behind this decision?
        4. What are we trying to discover or validate?

        Respond in JSON format:
        {{
            "recommended_tool": "tool_name",
            "reasoning": "why this tool should be used next",
            "parameters": {{"key": "value"}},
            "expected_outcome": "what we hope to discover",
            "priority": "high|medium|low",
            "task_type": "reconnaissance|vulnerability_assessment|exploitation|reporting"
        }}
        """
        
        try:
            # Get AI model decision
            if self.ollama_manager.client:
                response = self.ollama_manager.client.generate(
                    model=self.ollama_manager.model_name,
                    prompt=prompt
                )
                
                # Handle response properly - Ollama returns a dict
                if isinstance(response, dict):
                    response_text = response.get('response', '').strip()
                else:
                    response_text = str(response).strip()
            else:
                logger.warning("Ollama client not available, using fallback decision")
                return self._create_fallback_decision(current_state, agent_role)
            
            # Try to extract JSON from the response
            try:
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    decision = json.loads(json_match.group())
                    # Validate required fields
                    required_fields = ["recommended_tool", "reasoning", "priority", "task_type"]
                    for field in required_fields:
                        if field not in decision:
                            logger.warning(f"Missing field {field} in AI decision, using fallback")
                            decision = self._create_fallback_decision(current_state, agent_role)
                            break
                else:
                    # Fallback decision if JSON parsing fails
                    logger.warning("No JSON found in AI response, using fallback decision")
                    decision = self._create_fallback_decision(current_state, agent_role)
            except (json.JSONDecodeError, Exception) as parse_error:
                logger.warning(f"Failed to parse AI response: {parse_error}, using fallback decision")
                decision = self._create_fallback_decision(current_state, agent_role)
            
            # Log the AI decision
            self.mongodb.store_agent_action(
                agent_role="TaskPlanner",
                action_type="ai_task_decision",
                action_data={
                    "target": target,
                    "agent_role": agent_role,
                    "current_state": current_state,
                    "ai_response": response_text,
                    "decision": decision,
                    "timestamp": datetime.utcnow().isoformat()
                },
                pentest_session_id=self.session_id
            )
            
            return decision
            
        except Exception as e:
            logger.error(f"Error getting AI decision: {e}")
            return self._create_fallback_decision(current_state, agent_role)
    
    def _create_fallback_decision(self, current_state: Dict[str, Any], agent_role: str) -> Dict[str, Any]:
        """Create a fallback decision when AI model is not available"""
        completed_tools = set(current_state.get("completed_tools", []))
        
        # Rule-based fallback logic
        if agent_role == "Reconnaissance Specialist":
            if "nmap" not in completed_tools:
                return {
                    "recommended_tool": "nmap",
                    "reasoning": "Start with network reconnaissance to identify open ports and services",
                    "parameters": {},
                    "expected_outcome": "Discover open ports, services, and network topology",
                    "priority": "high",
                    "task_type": "reconnaissance"
                }
            elif "nikto" not in completed_tools:
                return {
                    "recommended_tool": "nikto",
                    "reasoning": "Perform web server vulnerability scanning",
                    "parameters": {},
                    "expected_outcome": "Identify web server vulnerabilities and misconfigurations",
                    "priority": "high",
                    "task_type": "reconnaissance"
                }
        
        elif agent_role == "Vulnerability Assessment Expert":
            if "sqlmap" not in completed_tools:
                return {
                    "recommended_tool": "sqlmap",
                    "reasoning": "Test for SQL injection vulnerabilities",
                    "parameters": {},
                    "expected_outcome": "Identify SQL injection points",
                    "priority": "high",
                    "task_type": "vulnerability_assessment"
                }
            elif "zap" not in completed_tools:
                return {
                    "recommended_tool": "zap",
                    "reasoning": "Comprehensive web application security testing",
                    "parameters": {},
                    "expected_outcome": "Identify web application vulnerabilities",
                    "priority": "medium",
                    "task_type": "vulnerability_assessment"
                }
        
        elif agent_role == "Exploitation Specialist":
            if "metasploit" not in completed_tools:
                return {
                    "recommended_tool": "metasploit",
                    "reasoning": "Search for applicable exploits based on discovered vulnerabilities",
                    "parameters": {},
                    "expected_outcome": "Identify potential exploitation paths",
                    "priority": "medium",
                    "task_type": "exploitation"
                }
        
        # Default recommendation
        return {
            "recommended_tool": "nmap",
            "reasoning": "Default reconnaissance tool for gathering basic information",
            "parameters": {},
            "expected_outcome": "Basic target information",
            "priority": "medium",
            "task_type": "reconnaissance"
        }

class PentestCrew:
    """CrewAI-based penetration testing crew with AI-guided task planning"""
    
    def __init__(self):
        self.ollama_manager = OllamaManager()
        self.tool_manager = ToolManager()
        self.mongodb = CrewAIMongoDB()  # Initialize MongoDB integration
        self.session_id = str(uuid.uuid4())  # Unique session ID for this instance
        self.task_planner = TaskPlanner(self.ollama_manager, self.mongodb, self.session_id)
        self.agents = self._create_agents()
        self.tasks = []
        
        # Log crew initialization
        if self.mongodb.is_connected():
            self.mongodb.store_agent_action(
                agent_role="PentestCrew",
                action_type="crew_initialized",
                action_data={
                    "session_id": self.session_id,
                    "available_tools": self.tool_manager.get_available_tools(),
                    "ai_guidance_enabled": True,
                    "initialized_at": datetime.utcnow().isoformat()
                },
                pentest_session_id=self.session_id
            )
        
    def _create_agents(self):
        """Create specialized penetration testing agents"""
        
        # Try to get LLM instance, fallback to None if not available
        try:
            llm_instance = self.ollama_manager.get_llm_instance()
            logger.info("LLM instance created successfully for agents")
        except Exception as e:
            logger.warning(f"Could not create LLM instance: {e}. Agents will use default behavior.")
            llm_instance = None
        
        # Reconnaissance Agent
        recon_agent = Agent(
            role='Reconnaissance Specialist',
            goal='Gather comprehensive information about the target system using available penetration testing tools',
            backstory="""You are an expert reconnaissance specialist with years of experience 
            in information gathering and target analysis. You excel at discovering system 
            information, network topology, and potential entry points. You have access to 
            tools like nmap, enum4linux, and nikto for comprehensive reconnaissance.""",
            verbose=True,
            allow_delegation=False,
            llm=llm_instance
        )
        
        # Vulnerability Assessment Agent
        vuln_agent = Agent(
            role='Vulnerability Assessment Expert',
            goal='Identify and analyze security vulnerabilities using specialized tools',
            backstory="""You are a seasoned vulnerability assessment expert with deep knowledge 
            of security flaws, CVE databases, and exploit techniques. You can identify 
            critical vulnerabilities and assess their potential impact. You have access to 
            tools like sqlmap, OWASP ZAP, Burp Suite, and Nikto for comprehensive vulnerability assessment.""",
            verbose=True,
            allow_delegation=False,
            llm=llm_instance
        )
        
        # Exploitation Agent
        exploit_agent = Agent(
            role='Exploitation Specialist',
            goal='Safely demonstrate and validate identified vulnerabilities using penetration testing tools',
            backstory="""You are an ethical hacking expert specializing in controlled 
            exploitation for security testing. You focus on proof-of-concept demonstrations 
            while maintaining system integrity and following ethical guidelines. You have access
            to tools like Metasploit, Hydra, and John the Ripper for controlled exploitation testing.""",
            verbose=True,
            allow_delegation=False,
            llm=llm_instance
        )
        
        # Report Generation Agent
        report_agent = Agent(
            role='Security Report Analyst',
            goal='Generate comprehensive and actionable security reports from tool outputs',
            backstory="""You are a skilled security analyst who excels at creating 
            detailed, actionable security reports. You can translate technical findings 
            into clear recommendations for both technical and non-technical stakeholders.
            You can analyze outputs from various penetration testing tools and create unified reports.""",
            verbose=True,
            allow_delegation=False,
            llm=llm_instance
        )
        
        return {
            'recon': recon_agent,
            'vulnerability': vuln_agent,
            'exploitation': exploit_agent,
            'reporting': report_agent
        }
    
    def execute_tool(self, tool_name: str, target: str, **kwargs) -> str:
        """Execute a specific penetration testing tool with comprehensive logging"""
        
        # Log tool execution start
        if self.mongodb.is_connected():
            self.mongodb.store_agent_action(
                agent_role="PentestCrew",
                action_type="tool_execution_start",
                action_data={
                    "tool_name": tool_name,
                    "target": target,
                    "kwargs": kwargs,
                    "started_at": datetime.utcnow().isoformat()
                },
                pentest_session_id=self.session_id
            )
        
        try:
            tool = self.tool_manager.get_tool(tool_name)
            result = tool.scan(target, **kwargs)
            
            # Log successful tool execution
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role="PentestCrew",
                    action_type="tool_execution_complete",
                    action_data={
                        "tool_name": tool_name,
                        "target": target,
                        "success": result.success,
                        "output_length": len(result.output),
                        "metadata": result.metadata,
                        "completed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=self.session_id
                )
                
                # Store detailed tool results
                tool_result_data = {
                    "success": result.success,
                    "output": result.output,
                    "metadata": result.metadata,
                    "kwargs": kwargs,
                    "session_id": self.session_id
                }
                mongodb_id = self.mongodb.store_tool_result(tool_name, target, tool_result_data)
                
                # Store command execution log
                self.mongodb.store_command_execution(
                    command=f"{tool_name} --target {target} {' '.join([f'--{k} {v}' for k, v in kwargs.items()])}",
                    output=result.output,
                    success=result.success,
                    context={
                        "tool_name": tool_name,
                        "target": target,
                        "session_id": self.session_id,
                        "mongodb_result_id": mongodb_id
                    }
                )
                
                if mongodb_id:
                    logger.info(f"Tool results ({tool_name}) saved to MongoDB with ID: {mongodb_id}")
                else:
                    logger.warning(f"Failed to save tool results ({tool_name}) to MongoDB")
            
            return f"Tool: {tool_name}\nTarget: {target}\nSuccess: {result.success}\nOutput:\n{result.output}\n\nMetadata: {result.metadata}"
            
        except Exception as e:
            # Log tool execution error
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role="PentestCrew",
                    action_type="tool_execution_error",
                    action_data={
                        "tool_name": tool_name,
                        "target": target,
                        "error": str(e),
                        "failed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=self.session_id
                )
                
                # Store error command execution
                self.mongodb.store_command_execution(
                    command=f"{tool_name} --target {target} {' '.join([f'--{k} {v}' for k, v in kwargs.items()])}",
                    output=f"Error: {str(e)}",
                    success=False,
                    context={
                        "tool_name": tool_name,
                        "target": target,
                        "session_id": self.session_id,
                        "error": str(e)
                    }
                )
                
                # Save error to MongoDB as well
                error_data = {
                    "success": False,
                    "output": "",
                    "error": str(e),
                    "metadata": {},
                    "kwargs": kwargs,
                    "session_id": self.session_id
                }
                self.mongodb.store_tool_result(tool_name, target, error_data)
            
            return f"Tool: {tool_name} failed with error: {str(e)}"
    
    def get_available_tools(self) -> List[str]:
        """Get list of available penetration testing tools"""
        return self.tool_manager.get_available_tools()
    
    def get_recent_pentest_results(self, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get recent penetration test results from MongoDB
        
        Args:
            limit: Maximum number of results to return
            
        Returns:
            List of recent pentest results
        """
        if not self.mongodb.is_connected():
            logger.warning("MongoDB not connected - cannot retrieve results")
            return []
        
        return self.mongodb.get_pentest_results(limit=limit)
    
    def get_tool_results(self, tool_name: Optional[str] = None, target: Optional[str] = None, limit: int = 10) -> List[Dict[str, Any]]:
        """
        Get tool execution results from MongoDB
        
        Args:
            tool_name: Filter by specific tool name
            target: Filter by specific target
            limit: Maximum number of results to return
            
        Returns:
            List of tool execution results
        """
        if not self.mongodb.is_connected():
            logger.warning("MongoDB not connected - cannot retrieve tool results")
            return []
        
        return self.mongodb.get_tool_results(tool_name=tool_name, target=target, limit=limit)
    
    def get_database_stats(self) -> Dict[str, Any]:
        """
        Get MongoDB database statistics
        
        Returns:
            Dictionary with database statistics
        """
        return self.mongodb.get_stats()
    
    def get_agent_actions(self, agent_role: Optional[str] = None, session_id: Optional[str] = None, limit: int = 50) -> List[Dict[str, Any]]:
        """
        Get agent actions and decisions from MongoDB
        
        Args:
            agent_role: Filter by specific agent role
            session_id: Filter by specific session
            limit: Maximum number of results to return
            
        Returns:
            List of agent actions
        """
        if not self.mongodb.is_connected():
            logger.warning("MongoDB not connected - cannot retrieve agent actions")
            return []
        
        return self.mongodb.get_agent_actions(agent_role=agent_role, pentest_session_id=session_id, limit=limit)
    
    def get_command_executions(self, limit: int = 50) -> List[Dict[str, Any]]:
        """
        Get command executions and their outputs
        
        Args:
            limit: Maximum number of results to return
            
        Returns:
            List of command executions
        """
        if not self.mongodb.is_connected():
            logger.warning("MongoDB not connected - cannot retrieve command executions")
            return []
        
        return self.mongodb.get_command_executions(limit=limit)
    
    def get_session_summary(self, session_id: str) -> Dict[str, Any]:
        """
        Get a comprehensive summary of a specific pentest session
        
        Args:
            session_id: The session ID to get summary for
            
        Returns:
            Dictionary with session summary
        """
        if not self.mongodb.is_connected():
            return {"error": "MongoDB not connected"}
        
        try:
            # Get all data for this session
            agent_actions = self.mongodb.get_agent_actions(pentest_session_id=session_id, limit=1000)
            tool_results = self.mongodb.get_tool_results(limit=1000)
            command_executions = self.mongodb.get_command_executions(limit=1000)
            pentest_results = self.mongodb.get_pentest_results(limit=10)
            
            # Filter data for this session
            session_tools = [t for t in tool_results if t.get('result_data', {}).get('session_id') == session_id]
            session_commands = [c for c in command_executions if c.get('context', {}).get('session_id') == session_id]
            session_pentests = [p for p in pentest_results if p.get('session_id') == session_id]
            
            return {
                "session_id": session_id,
                "agent_actions": len(agent_actions),
                "tool_executions": len(session_tools),
                "command_executions": len(session_commands),
                "pentest_results": len(session_pentests),
                "summary": {
                    "tools_used": list(set([t.get('tool_name') for t in session_tools])),
                    "agents_active": list(set([a.get('agent_role') for a in agent_actions])),
                    "action_types": list(set([a.get('action_type') for a in agent_actions])),
                    "success_rate": len([t for t in session_tools if t.get('result_data', {}).get('success')]) / max(len(session_tools), 1) * 100
                }
            }
            
        except Exception as e:
            return {"error": f"Error getting session summary: {e}"}
    
    def _create_tasks(self, target: str, scope: str, additional_params: Dict[str, Any]):
        """Create tasks for the penetration testing workflow"""
        
        # Reconnaissance Task
        recon_task = Task(
            description=f"""
            Perform comprehensive reconnaissance on the target: {target}
            
            Your analysis should include:
            1. Domain and subdomain enumeration
            2. Port scanning and service identification
            3. Technology stack identification
            4. Public information gathering
            5. Social engineering reconnaissance (if in scope)
            
            Scope: {scope}
            Additional parameters: {additional_params}
            
            Provide a detailed reconnaissance report with all findings.
            """,
            agent=self.agents['recon'],
            expected_output="Detailed reconnaissance report with discovered assets, services, and potential attack vectors"
        )
        
        # Vulnerability Assessment Task
        vuln_task = Task(
            description=f"""
            Based on the reconnaissance findings, perform a thorough vulnerability assessment on {target}
            
            Your assessment should include:
            1. Known vulnerability identification (CVE lookup)
            2. Configuration weaknesses analysis
            3. Web application security testing (if applicable)
            4. Network security assessment
            5. Risk prioritization and CVSS scoring
            
            Focus on vulnerabilities within the scope: {scope}
            """,
            agent=self.agents['vulnerability'],
            expected_output="Comprehensive vulnerability assessment report with risk ratings and exploitation potential"
        )
        
        # Exploitation Task
        exploit_task = Task(
            description=f"""
            Safely validate and demonstrate the identified vulnerabilities for {target}
            
            Your exploitation should include:
            1. Proof-of-concept development for critical vulnerabilities
            2. Safe exploitation techniques (no data destruction)
            3. Privilege escalation attempts (if applicable)
            4. Lateral movement possibilities
            5. Impact demonstration
            
            IMPORTANT: Only perform safe, non-destructive testing within scope: {scope}
            """,
            agent=self.agents['exploitation'],
            expected_output="Exploitation report with proof-of-concept demonstrations and impact assessment"
        )
        
        # Reporting Task
        report_task = Task(
            description=f"""
            Generate a comprehensive penetration testing report for {target}
            
            Your report should include:
            1. Executive summary with key findings
            2. Technical details of all discovered vulnerabilities
            3. Risk assessment and prioritization
            4. Detailed remediation recommendations
            5. Appendices with technical evidence
            
            Ensure the report is suitable for both technical teams and management.
            """,
            agent=self.agents['reporting'],
            expected_output="Professional penetration testing report with executive summary and technical details"
        )
        
        return [recon_task, vuln_task, exploit_task, report_task]
    
    async def execute_pentest(self, target: str, scope: str = "basic", additional_params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Execute the complete penetration testing workflow with comprehensive logging"""
        
        if additional_params is None:
            additional_params = {}
            
        # Create a new session ID for this pentest
        pentest_session_id = str(uuid.uuid4())
        
        try:
            logger.info(f"Initializing pentest crew for target: {target}")
            
            # Log pentest session start
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role="PentestCrew",
                    action_type="pentest_session_start",
                    action_data={
                        "target": target,
                        "scope": scope,
                        "additional_params": additional_params,
                        "session_id": pentest_session_id,
                        "started_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=pentest_session_id
                )
            
            # Try to ensure Ollama model is available, but don't fail if it's not
            try:
                model_available = await self.ollama_manager.ensure_model_available()
                if not model_available:
                    logger.warning("Ollama model not available. Using fallback mode.")
                    
                    if self.mongodb.is_connected():
                        self.mongodb.store_agent_action(
                            agent_role="PentestCrew",
                            action_type="ollama_fallback",
                            action_data={
                                "message": "Ollama model not available, using fallback mode",
                                "timestamp": datetime.utcnow().isoformat()
                            },
                            pentest_session_id=pentest_session_id
                        )
            except Exception as e:
                logger.warning(f"Could not initialize Ollama: {e}. Using fallback mode.")
                
                if self.mongodb.is_connected():
                    self.mongodb.store_agent_action(
                        agent_role="PentestCrew",
                        action_type="ollama_error",
                        action_data={
                            "error": str(e),
                            "message": "Could not initialize Ollama, using fallback mode",
                            "timestamp": datetime.utcnow().isoformat()
                        },
                        pentest_session_id=pentest_session_id
                    )
            
            # Execute AI-guided penetration testing
            results = await self.execute_ai_guided_pentest(target, scope, additional_params, pentest_session_id)
            
            return results
            
        except Exception as e:
            logger.error(f"Error in pentest execution: {e}")
            
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role="PentestCrew",
                    action_type="pentest_session_error",
                    action_data={
                        "target": target,
                        "error": str(e),
                        "session_id": pentest_session_id,
                        "failed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=pentest_session_id
                )
            
            return {"error": str(e), "session_id": pentest_session_id}
    
    async def execute_ai_guided_pentest(self, target: str, scope: str, additional_params: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Execute penetration testing with AI-guided task planning"""
        
        results = {
            "session_id": session_id,
            "target": target,
            "scope": scope,
            "phases": {},
            "summary": {}
        }
        
        # Define the penetration testing phases
        phases = [
            ("reconnaissance", "Reconnaissance Specialist"),
            ("vulnerability_assessment", "Vulnerability Assessment Expert"),
            ("exploitation", "Exploitation Specialist"),
            ("reporting", "Security Report Analyst")
        ]
        
        for phase_name, agent_role in phases:
            logger.info(f"Starting {phase_name} phase with {agent_role}")
            
            # Let AI decide the next tasks for this phase
            phase_results = await self.execute_ai_guided_phase(target, agent_role, phase_name, session_id)
            results["phases"][phase_name] = phase_results
            
            # Log phase completion
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role=agent_role,
                    action_type="phase_completed",
                    action_data={
                        "phase": phase_name,
                        "target": target,
                        "results_summary": {
                            "tasks_executed": len(phase_results.get("tasks", [])),
                            "tools_used": phase_results.get("tools_used", []),
                            "success": phase_results.get("success", False)
                        },
                        "completed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=session_id
                )
        
        # Generate final summary
        results["summary"] = self.generate_pentest_summary(results, session_id)
        
        # Store final results in MongoDB
        if self.mongodb.is_connected():
            results["target"] = target
            results["session_id"] = session_id
            mongodb_result_id = self.mongodb.store_pentest_result(results)
            results["mongodb_id"] = mongodb_result_id
            logger.info(f"Pentest results stored in MongoDB with ID: {mongodb_result_id}")
        
        return results
    
    async def execute_ai_guided_phase(self, target: str, agent_role: str, phase_name: str, session_id: str) -> Dict[str, Any]:
        """Execute a single phase with AI-guided task selection"""
        
        phase_results = {
            "phase": phase_name,
            "agent": agent_role,
            "tasks": [],
            "tools_used": [],
            "success": True,
            "findings": []
        }
        
        max_tasks_per_phase = 5  # Limit tasks per phase to prevent infinite loops
        
        for task_num in range(max_tasks_per_phase):
            # Get AI decision for next task
            decision = self.task_planner.decide_next_task(target, agent_role)
            
            # Validate decision structure
            if not isinstance(decision, dict) or "recommended_tool" not in decision:
                logger.error(f"Invalid decision structure from AI: {decision}")
                # Create a fallback decision
                decision = self.task_planner._create_fallback_decision(
                    self.task_planner.analyze_current_state(target), 
                    agent_role
                )
            
            recommended_tool = decision.get("recommended_tool", "nmap")
            logger.info(f"AI Decision for {agent_role} (Task {task_num + 1}): {recommended_tool}")
            
            # Check if this tool has already been used in this phase
            if recommended_tool in phase_results["tools_used"]:
                logger.info(f"Tool {recommended_tool} already used in this phase, moving to next")
                continue
            
            # Execute the recommended task
            task_result = await self.execute_ai_guided_task(target, decision, agent_role, session_id)
            
            # Add to phase results
            phase_results["tasks"].append(task_result)
            phase_results["tools_used"].append(recommended_tool)
            
            # Extract findings from the task result
            if task_result.get("success") and task_result.get("output"):
                phase_results["findings"].append({
                    "tool": decision["recommended_tool"],
                    "finding": task_result["output"][:300] + "..." if len(task_result.get("output", "")) > 300 else task_result.get("output", "")
                })
            
            # If this was a low priority task or we have enough findings, consider moving to next phase
            if decision.get("priority") == "low" and len(phase_results["findings"]) >= 2:
                logger.info(f"Phase {phase_name} has sufficient findings, moving to next phase")
                break
        
        return phase_results
    
    async def execute_ai_guided_task(self, target: str, decision: Dict[str, Any], agent_role: str, session_id: str) -> Dict[str, Any]:
        """Execute a single AI-guided task"""
        
        # Validate decision structure and provide defaults
        tool_name = decision.get("recommended_tool", "nmap")
        parameters = decision.get("parameters", {})
        reasoning = decision.get("reasoning", "AI-guided task execution")
        expected_outcome = decision.get("expected_outcome", "Gather security information")
        priority = decision.get("priority", "medium")
        
        # Log task execution start
        if self.mongodb.is_connected():
            self.mongodb.store_agent_action(
                agent_role=agent_role,
                action_type="ai_guided_task_start",
                action_data={
                    "tool": tool_name,
                    "target": target,
                    "reasoning": reasoning,
                    "expected_outcome": expected_outcome,
                    "priority": priority,
                    "parameters": parameters,
                    "started_at": datetime.utcnow().isoformat()
                },
                pentest_session_id=session_id
            )
        
        try:
            # Execute the tool
            result = self.execute_tool(tool_name, target, **parameters)
            
            # Parse the result
            task_result = {
                "tool": tool_name,
                "target": target,
                "success": "Success: True" in result or "success: True" in result,
                "output": result,
                "reasoning": reasoning,
                "expected_outcome": expected_outcome,
                "priority": priority,
                "executed_at": datetime.utcnow().isoformat()
            }
            
            # Log task completion
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role=agent_role,
                    action_type="ai_guided_task_complete",
                    action_data={
                        "tool": tool_name,
                        "target": target,
                        "success": task_result["success"],
                        "output_length": len(task_result["output"]),
                        "completed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=session_id
                )
            
            return task_result
            
        except Exception as e:
            logger.error(f"Error executing AI-guided task {tool_name}: {e}")
            
            task_result = {
                "tool": tool_name,
                "target": target,
                "success": False,
                "output": f"Error: {str(e)}",
                "error": str(e),
                "executed_at": datetime.utcnow().isoformat()
            }
            
            # Log task error
            if self.mongodb.is_connected():
                self.mongodb.store_agent_action(
                    agent_role=agent_role,
                    action_type="ai_guided_task_error",
                    action_data={
                        "tool": tool_name,
                        "target": target,
                        "error": str(e),
                        "failed_at": datetime.utcnow().isoformat()
                    },
                    pentest_session_id=session_id
                )
            
            return task_result
    
    def generate_pentest_summary(self, results: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Generate a summary of the penetration testing results"""
        
        summary = {
            "total_phases": len(results.get("phases", {})),
            "total_tools_used": [],
            "total_findings": 0,
            "vulnerabilities_found": 0,
            "success_rate": 0,
            "recommendations": []
        }
        
        successful_tasks = 0
        total_tasks = 0
        
        for phase_name, phase_data in results.get("phases", {}).items():
            if isinstance(phase_data, dict):
                summary["total_tools_used"].extend(phase_data.get("tools_used", []))
                summary["total_findings"] += len(phase_data.get("findings", []))
                
                for task in phase_data.get("tasks", []):
                    total_tasks += 1
                    if task.get("success"):
                        successful_tasks += 1
                    
                    # Count potential vulnerabilities
                    output = task.get("output", "").lower()
                    if any(keyword in output for keyword in ["vulnerability", "exploit", "weak", "missing", "exposed"]):
                        summary["vulnerabilities_found"] += 1
        
        # Remove duplicates and calculate success rate
        summary["total_tools_used"] = list(set(summary["total_tools_used"]))
        summary["success_rate"] = (successful_tasks / max(total_tasks, 1)) * 100
        
        # Generate recommendations based on findings
        if summary["vulnerabilities_found"] > 0:
            summary["recommendations"].append("High priority: Address identified vulnerabilities immediately")
        if summary["total_findings"] < 5:
            summary["recommendations"].append("Medium priority: Consider more comprehensive testing")
        
        summary["recommendations"].append("Monitor and re-test after remediation")
        
        return summary
